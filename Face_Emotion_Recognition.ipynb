{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaithanyaNadithoka/Face-Emotion-Recognition-using-GoogleNet-ONNX/blob/main/Face_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime opencv-python-headless pillow numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsNl9e3WaolD",
        "outputId": "5c7d4c22-c067-42ea-a8ca-0c1e04964d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "zxPJ-oN0JEOz",
        "outputId": "517466f5-7d8a-4653-afd2-708ae89ad4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Input Shape: ['BatchSize', 3, 224, 224]\n",
            "Detected Faces: [[ 4  4 39 39]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized Emotions: ['Disgust']\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def recognize_emotion(photo_content):\n",
        "    # Path to your ONNX model\n",
        "    onnx_model_path = \"model2.onnx\"  # Ensure this file is uploaded to the same directory\n",
        "\n",
        "    # Load the ONNX model\n",
        "    session = onnxruntime.InferenceSession(onnx_model_path)\n",
        "\n",
        "    # Get the input shape dynamically\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    input_shape = session.get_inputs()[0].shape  # (BatchSize, Channels, Height, Width)\n",
        "    print(\"Model Input Shape:\", input_shape)\n",
        "\n",
        "    # Load the input image\n",
        "    original_image = Image.open(BytesIO(photo_content)).convert(\"RGB\")  # Ensure it's in RGB mode\n",
        "    input_image = np.array(original_image)\n",
        "\n",
        "    # Detect faces in the original image\n",
        "    faces = detect_faces(input_image)\n",
        "\n",
        "    # Variables to store emotion predictions for each face\n",
        "    face_emotions = []\n",
        "\n",
        "    # If faces are detected, proceed with emotion recognition for each face\n",
        "    if len(faces) > 0:\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Draw a rectangle around the detected face\n",
        "            cv2.rectangle(input_image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "            # Crop the detected face region\n",
        "            face_region = input_image[y:y + h, x:x + w]\n",
        "\n",
        "            # Resize the face to the expected input shape (Height, Width)\n",
        "            resized_face = cv2.resize(face_region, (224, 224))\n",
        "\n",
        "            # Ensure the face region has 3 channels (convert grayscale to RGB if needed)\n",
        "            if len(resized_face.shape) == 2:  # Grayscale image\n",
        "                resized_face = cv2.cvtColor(resized_face, cv2.COLOR_GRAY2RGB)\n",
        "            elif resized_face.shape[2] != 3:  # If not RGB\n",
        "                resized_face = resized_face[:, :, :3]\n",
        "\n",
        "            # Convert the resized face to the format (BatchSize, Channels, Height, Width)\n",
        "            input_array = np.expand_dims(resized_face, axis=0)  # Add BatchSize dimension\n",
        "            input_array = np.transpose(input_array, (0, 3, 1, 2))  # Change to (N, C, H, W)\n",
        "\n",
        "            # Perform emotion recognition for the resized face\n",
        "            result = session.run([], {input_name: input_array.astype(np.float32)})\n",
        "\n",
        "            # Process and store the emotion prediction for the current face\n",
        "            face_emotion = process_output(result[0])\n",
        "            face_emotions.append(face_emotion)\n",
        "\n",
        "            # Print the emotion label near the rectangle\n",
        "            cv2.putText(input_image, face_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 66, 247), 2)\n",
        "\n",
        "        # Return the image with rectangles and emotions\n",
        "        return input_image, face_emotions\n",
        "\n",
        "    else:\n",
        "        print(\"No faces detected.\")\n",
        "        return input_image, []\n",
        "\n",
        "def process_output(output_array):\n",
        "    # Assuming output_array is an array of probabilities for each class\n",
        "    emotion_labels = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise']\n",
        "    max_prob_index = np.argmax(output_array)\n",
        "    recognized_label = emotion_labels[max_prob_index]\n",
        "    return recognized_label\n",
        "\n",
        "def detect_faces(image):\n",
        "    # Load OpenCV's pre-trained Haar Cascade face detector\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    # Convert to grayscale for face detection\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    print(\"Detected Faces:\", faces)\n",
        "    return faces\n",
        "\n",
        "# Load the input image (anger.png)\n",
        "with open(\"disgust.png\", \"rb\") as img_file:\n",
        "    photo_content = img_file.read()\n",
        "\n",
        "# Run the recognition\n",
        "output_image, emotions = recognize_emotion(photo_content)\n",
        "\n",
        "# Display the processed image with rectangles and labels\n",
        "output_image = Image.fromarray(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# Show the image with emotions\n",
        "plt.imshow(output_image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Print the recognized emotions\n",
        "print(\"Recognized Emotions:\", emotions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WHFx8XaPEXPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}